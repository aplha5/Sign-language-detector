# Sign-language to text and speech convertor
# Overview
Sign language is an essential tool for the deaf and dumb community to communicate effectively with the world. To enhance this communication, I developed a real-time Sign Language to Text and Speech Converter. This project leverages OpenCV and advanced machine learning techniques, primarily Convolutional Neural Networks (CNNs) and Random Forest classifiers. The system captures human gestures via a camera and identifies hand landmarks using MediaPipe, which employs CNNs. The data is then trained and tested using Random Forest classifiers. The recognized gestures are first converted to text, which is subsequently transformed into speech using pyttsx3. This innovative solution aims to bridge communication gaps and facilitate seamless interaction for individuals with hearing and speech impairments.

The result of the project is 

# Inroduction
Sign language is a crucial tool for individuals who are deaf and dumb, allowing them to communicate effectively through hand signs since they cannot speak. Communication involves the exchange of messages, which can be done through signals, speech, or text. For those who are deaf and dumb, sign language simplifies communication. However, not everyone understands sign language. To bridge this gap, I developed a system that can detect hand signs representing letters, convert these signs into text, and subsequently transform the text into speech. This makes communication more accessible and seamless for individuals with hearing and speech disabilities.
The below attached photo consists of the Aplhabet sign Language
![Screenshot (57)](https://github.com/user-attachments/assets/a04267ea-f89b-4219-9f41-bb3d873eb4b9)
